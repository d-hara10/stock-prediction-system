{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e487d807-906a-4006-96dd-30377b9cf608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6c8bc4bd-fc78-4a2d-aa00-4e215384463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Fetching\n",
    "def fetch_data(ticker: str, start: str = None, end: str = None) -> pd.DataFrame:\n",
    "\n",
    "    if start is None:\n",
    "        start = (datetime.today() - pd.DateOffset(years = 2)).strftime(\"%Y-%m-%d\")\n",
    "    if end is None:\n",
    "        end = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "    data = yf.download(ticker, start=start, end=end, group_by=\"column\", auto_adjust = True)\n",
    "    # Flatten MultiIndex columns if necessary\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        data.columns = [col[0] for col in data.columns]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8dcb6a8d-1ad4-401e-b571-7bd4c3da3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Basic Returns\n",
    "    data[\"Return\"] = data[\"Close\"].pct_change()\n",
    "\n",
    "    for lag in [1, 2, 3, 5]:\n",
    "        data[f\"Return_Lag_{lag}\"] = data[\"Return\"].shift(lag)\n",
    "\n",
    "    # RSI (Wilder's smoothing)\n",
    "    delta = data[\"Close\"].diff()\n",
    "\n",
    "    data[\"gain\"] = np.where(delta > 0, delta, 0)\n",
    "    data[\"loss\"] = np.where(delta < 0, -delta, 0)\n",
    "\n",
    "    data[\"avg_gain\"] = data[\"gain\"].ewm(alpha=1/14, adjust=False).mean()\n",
    "    data[\"avg_loss\"] = data[\"loss\"].ewm(alpha=1/14, adjust=False).mean()\n",
    "\n",
    "    rs = data[\"avg_gain\"] / (data[\"avg_loss\"] + 1e-10)\n",
    "    data[\"RSI\"] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    data.drop(columns=[\"gain\", \"loss\", \"avg_gain\", \"avg_loss\"], inplace=True)\n",
    "\n",
    "    # MACD\n",
    "    ema12 = data[\"Close\"].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = data[\"Close\"].ewm(span=26, adjust=False).mean()\n",
    "\n",
    "    data[\"MACD\"] = ema12 - ema26\n",
    "    data[\"MACD_Signal\"] = data[\"MACD\"].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    # Bollinger Bands\n",
    "\n",
    "    sma20 = data[\"Close\"].rolling(window=20).mean()\n",
    "    std20 = data[\"Close\"].rolling(window=20).std()\n",
    "\n",
    "    data[\"BB_Upper\"] = sma20 + 2 * std20\n",
    "    data[\"BB_Lower\"] = sma20 - 2 * std20\n",
    "    data[\"BB_Width\"] = data[\"BB_Upper\"] - data[\"BB_Lower\"]\n",
    "\n",
    "    # Rolling & Historical Volatility\n",
    "    data[\"RollingVolatility\"] = data[\"Return\"].rolling(window=20).std()\n",
    "\n",
    "    for window in [10, 20, 30]:\n",
    "        data[f\"HV_{window}\"] = data[\"Return\"].rolling(window).std()\n",
    "\n",
    "    # ATR (Wilder optional)\n",
    "    data[\"High-Low\"] = data[\"High\"] - data[\"Low\"]\n",
    "    data[\"High-Close\"] = np.abs(data[\"High\"] - data[\"Close\"].shift())\n",
    "    data[\"Low-Close\"] = np.abs(data[\"Low\"] - data[\"Close\"].shift())\n",
    "\n",
    "    data[\"TR\"] = data[[\"High-Low\", \"High-Close\", \"Low-Close\"]].max(axis=1)\n",
    "    data[\"ATR\"] = data[\"TR\"].ewm(alpha=1/14, adjust=False).mean()\n",
    "\n",
    "    data.drop(columns=[\"High-Low\", \"High-Close\", \"Low-Close\", \"TR\"], inplace=True)\n",
    "\n",
    "    # Momentum\n",
    "    data[\"RollingMean\"] = data[\"Return\"].rolling(window=10).mean()\n",
    "\n",
    "    # Target Volatility\n",
    "    data[\"TargetVolatility\"] = data[\"RollingVolatility\"].shift(-1)\n",
    "\n",
    "    # Drop Warmup + Last Row\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0a7540d4-8a20-4bfc-aebd-91b3e601a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"RollingVolatility\", \"ATR\", \"RollingMean\", \"Return\",\n",
    "    \"RSI\", \"MACD\", \"MACD_Signal\",\n",
    "    \"BB_Width\",\n",
    "    \"Return_Lag_1\", \"Return_Lag_2\", \"Return_Lag_3\", \"Return_Lag_5\",\n",
    "    \"HV_10\", \"HV_20\", \"HV_30\"]\n",
    "\n",
    "# Prepare Features & Target\n",
    "def prepare_X_y(data: pd.DataFrame, feature_list):\n",
    "    X = data[feature_list]\n",
    "    y = data[\"TargetVolatility\"]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e6b9f7b1-9a24-4a81-86dc-f486966153a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model with GridSearchCV & TimeSeriesSplit\n",
    "def train_model(X_train, y_train):\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [None, 5, 10, 20],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "    }\n",
    "    \n",
    "    rf = RandomForestRegressor(random_state=123)\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=rf,\n",
    "        param_grid=param_grid,\n",
    "        cv=tscv,\n",
    "        n_jobs=-1,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_rf = grid_search.best_estimator_\n",
    "    \n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    return best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4241b0cb-4669-4ccf-872c-a48d072289a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "def evaluate_model_metrics(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Returns evaluation metrics for the model on test data.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Mean Absolute Error: {mae:.6f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    \n",
    "    return y_pred, mae, r2\n",
    "\n",
    "def plot_predictions(y_test, y_pred, data_index, ticker=\"TICKER\"):\n",
    "    \"\"\"\n",
    "    Plots actual vs predicted volatility.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(data_index[-len(y_test):], y_test, label=\"Actual\", linewidth=2)\n",
    "    plt.plot(data_index[-len(y_test):], y_pred, label=\"Predicted\", linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.title(f\"{ticker} Volatility Prediction (Time-Series GridSearchCV)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "56cca316-7941-40d3-a491-0753f95a7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_paths(ticker: str, model_dir: str = \"models\"):\n",
    "    \"\"\"\n",
    "    Returns the directory, model path, and metadata path for a given ticker.\n",
    "    \"\"\"\n",
    "    ticker_dir = os.path.join(model_dir, ticker)\n",
    "    model_path = os.path.join(ticker_dir, \"model.pkl\")\n",
    "    metadata_path = os.path.join(ticker_dir, \"metadata.json\")\n",
    "    return ticker_dir, model_path, metadata_path\n",
    "\n",
    "\n",
    "def save_model_and_metadata(ticker: str, model, model_dir: str = \"models\"):\n",
    "    \"\"\"\n",
    "    Saves the model and corresponding metadata (ticker, trained_on, version, features).\n",
    "    \"\"\"\n",
    "    ticker_dir, model_path, metadata_path = get_model_paths(ticker, model_dir)\n",
    "    os.makedirs(ticker_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(model, model_path)\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        \"ticker\": ticker,\n",
    "        \"trained_on\": datetime.now().isoformat(),\n",
    "        \"model_version\": \"v1.0\",\n",
    "        \"features\": features\n",
    "    }\n",
    "    \n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    \n",
    "    print(f\"Saved model to {model_path}\")\n",
    "    print(f\"Saved metadata to {metadata_path}\")\n",
    "\n",
    "\n",
    "def load_model_and_metadata(ticker: str, model_dir: str = \"models\"):\n",
    "    \"\"\"\n",
    "    Loads the model and metadata if they exist, otherwise returns (None, None).\n",
    "    \"\"\"\n",
    "    ticker_dir, model_path, metadata_path = get_model_paths(ticker, model_dir)\n",
    "    \n",
    "    if not os.path.exists(model_path) or not os.path.exists(metadata_path):\n",
    "        return None, None\n",
    "    \n",
    "    model = joblib.load(model_path)\n",
    "    with open(metadata_path, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    return model, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6cff354b-3d16-44fe-aa9e-f5d50c194aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_model_stale(metadata: dict, max_age_days: int = 30) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if model is older than max_age_days.\n",
    "    \"\"\"\n",
    "    trained_on_str = metadata.get(\"trained_on\")\n",
    "    if trained_on_str is None:\n",
    "        return True  # no trained date = treat as stale\n",
    "    \n",
    "    trained_on = datetime.fromisoformat(trained_on_str).date()\n",
    "    today = datetime.today().date()\n",
    "    age = (today - trained_on).days\n",
    "    \n",
    "    return age > max_age_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7363201c-807e-4651-96d3-39b022331851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Pipeline\n",
    "def run_pipeline(ticker: str, feature_list, plot: bool = False, model_dir: str = \"models\"):\n",
    "    \"\"\"\n",
    "    Runs the full volatility prediction pipeline for a given ticker.\n",
    "    \n",
    "    - If a saved, non-stale model exists, loads the model.\n",
    "    - Otherwise, trains a new model, saves it + metadata, and uses it.\n",
    "    \n",
    "    Returns:\n",
    "        model, X_test, y_test, y_pred\n",
    "    \"\"\"\n",
    "    # Fetch and process data\n",
    "    data = fetch_data(ticker)\n",
    "    data = compute_features(data)\n",
    "    X, y = prepare_X_y(data, features)\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "    # Try to load existing model + metadata\n",
    "    model, metadata = load_model_and_metadata(ticker, model_dir=model_dir)\n",
    "    \n",
    "    if model is not None and metadata is not None and not is_model_stale(metadata):\n",
    "        print(\n",
    "            f\"Loaded model v{metadata['model_version']} \"\n",
    "            f\"for {ticker} (trained_on={metadata['trained_on']})\"\n",
    "        )\n",
    "    else:\n",
    "        if model is None:\n",
    "            print(f\"No saved model for {ticker}. Training new model...\")\n",
    "        elif metadata is None:\n",
    "            print(f\"No metadata for {ticker}. Retraining model...\")\n",
    "        else:\n",
    "            print(f\"Model for {ticker} is stale. Retraining... (trained_on={metadata.get('trained_on')})\")\n",
    "        \n",
    "        model = train_model(X_train, y_train)\n",
    "        save_model_and_metadata(ticker, model, model_dir=model_dir)\n",
    "    \n",
    "    # Evaluate metrics\n",
    "    y_pred, mae, r2 = evaluate_model_metrics(model, X_test, y_test)\n",
    "    \n",
    "    # Optional plot\n",
    "    if plot:\n",
    "        plot_predictions(y_test, y_pred, data.index, ticker)\n",
    "    \n",
    "    return model, X_test, y_test, y_pred, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b1347e93-c8b1-4542-9806-4f01555e00d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing AAPL ===\n",
      "Loaded model vv1.0 for AAPL (trained_on=2025-11-29T15:16:00.553872)\n",
      "Mean Absolute Error: 0.000693\n",
      "R² Score: 0.9054\n",
      "AAPL -> RF MAE: 0.000693, GARCH MAE: 0.003339\n",
      "\n",
      "=== Processing TSLA ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model vv1.0 for TSLA (trained_on=2025-11-29T15:16:20.977134)\n",
      "Mean Absolute Error: 0.001593\n",
      "R² Score: 0.7254\n",
      "TSLA -> RF MAE: 0.001593, GARCH MAE: 0.010086\n",
      "\n",
      "=== Processing SPY ===\n",
      "Loaded model vv1.0 for SPY (trained_on=2025-11-29T15:16:42.001021)\n",
      "Mean Absolute Error: 0.000382\n",
      "R² Score: 0.8992\n",
      "SPY -> RF MAE: 0.000382, GARCH MAE: 0.003238\n"
     ]
    }
   ],
   "source": [
    "from arch import arch_model\n",
    "tickers = [\"AAPL\", \"TSLA\", \"SPY\"]\n",
    "\n",
    "# Store results for later visualization or analysis\n",
    "results = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"\\n=== Processing {ticker} ===\")\n",
    "\n",
    "    # Run ML model\n",
    "    model, X_test, y_test, y_pred, data = run_pipeline(ticker, feature_list = features, plot=False)\n",
    "\n",
    "    # Store RF metrics correctly\n",
    "    rf_mae = mean_absolute_error(y_test, y_pred)\n",
    "    rf_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Prepare returns for GARCH\n",
    "    garch_returns = data[\"Return\"].dropna() * 100\n",
    "    \n",
    "    # Fit GARCH\n",
    "    garch = arch_model(garch_returns, vol=\"Garch\", p=1, q=1)\n",
    "    garch_fit = garch.fit(disp=\"off\")\n",
    "\n",
    "    # Forecast GARCH volatility for test horizon\n",
    "    garch_forecast = garch_fit.forecast(horizon=len(y_test))\n",
    "    garch_vol = garch_forecast.variance.values[-1, :] ** 0.5 / 100\n",
    "\n",
    "    # Compute GARCH MAE\n",
    "    garch_mae = mean_absolute_error(y_test, garch_vol)\n",
    "\n",
    "    print(f\"{ticker} -> RF MAE: {rf_mae:.6f}, GARCH MAE: {garch_mae:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4478e1fb-a8e1-4d39-8d99-ada416c55c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
